{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module with neural network class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class is designed following \"Hands On Machine Learning\" by A.Geron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self,layers,batch_size,fl_name,regression=False):\n",
    "        self.regression=regression\n",
    "        if len(layers)<3:\n",
    "            raise ValueError\n",
    "        self.batch_size=batch_size\n",
    "        self.layers=layers\n",
    "        self.X=tf.placeholder(tf.float32,shape=(None,layers[0]),name=\"X\")\n",
    "        if regression:\n",
    "            self.y=tf.placeholder(tf.float32,shape=(None),name=\"y\")\n",
    "        else:\n",
    "            self.y=tf.placeholder(tf.int64,shape=(None),name=\"y\")\n",
    "        self.activations={\"ELU\":tf.nn.elu,\"RELU\":tf.nn.relu,\"SIG\":tf.nn.sigmoid,\"TANH\":tf.nn.tanh,\"SOFT\":tf.nn.softplus}\n",
    "\n",
    "        self.tr_err=[]\n",
    "        self.val_err=[]\n",
    "        self.filename=\"./\"+fl_name+\".ckpt\"\n",
    "    \n",
    "    def create_network(self,learning_rate,activ=\"ELU\",optim=\"SGD\",initialization=\"HE\"):\n",
    "        with tf.name_scope(\"dnn\"):\n",
    "            if initialization==\"HE\":\n",
    "                he_init=tf.contrib.layers.variance_scaling_initializer()\n",
    "                self.H=[tf.layers.dense(self.X,self.layers[1],name=\"Hidden_layer1\",kernel_initializer=he_init,activation=self.activations[activ])]\n",
    "            else:\n",
    "                self.H=[tf.layers.dense(self.X,self.layers[1],name=\"Hidden_layer1\",activation=self.activations[activ])]\n",
    "\n",
    "            if len(self.layers)>3:\n",
    "                for i in range(2,len(self.layers)):\n",
    "                    self.H.append(tf.layers.dense(self.H[-1],self.layers[i],name=\"Hidden_layer\"+str(i),activation=self.activations[activ]))\n",
    "\n",
    "            self.logits=tf.layers.dense(self.H[-1],self.layers[-1],name=\"Output_layer\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            if self.regression:\n",
    "                lsq=(tf.transpose(self.logits)-self.y)**2\n",
    "                self.loss=tf.reduce_mean(lsq,name=\"Loss\")\n",
    "            else:\n",
    "                xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y,logits=self.logits)\n",
    "                self.loss=tf.reduce_mean(xentropy,name=\"Loss\")\n",
    "\n",
    "        with tf.name_scope(\"train\"):\n",
    "            if optim==\"SGD\":\n",
    "                optimizer=tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            elif optim==\"MOM\":\n",
    "                optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "            elif optim==\"NMOM\":\n",
    "                optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9,use_nesterov=True)\n",
    "            elif optim==\"RMSP\":\n",
    "                optimizer=tf.train.RMSPropOptimizer(learinng_rate=learning_rate,momentum=0.9,decay=0.9,epsilon=1e-10)\n",
    "            elif optim==\"ADAM\":\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "            self.training_op=optimizer.minimize(self.loss)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"eval\"):\n",
    "            if self.regression:\n",
    "                correct=np.absolute(tf.transpose(self.logits)-self.y)\n",
    "                self.accuracy=tf.reduce_mean(correct)\n",
    "    \n",
    "            else:\n",
    "                correct=tf.nn.in_top_k(self.logits,self.y,1)\n",
    "                self.accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "    def train(self,Data_train,Labels_train,Data_eval,Labels_eval,n_epochs,save_model=False):\n",
    "\n",
    "        self.indices=np.arange(Data_train.shape[0])\n",
    "        \n",
    "        init=tf.global_variables_initializer()\n",
    "        \n",
    "        if save_model:\n",
    "            saver=tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            init.run()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                \n",
    "                np.random.shuffle(self.indices)\n",
    "                \n",
    "                for i in range(len(Data_train)//batch_size):\n",
    "                    X_batch,y_batch=self.get_batch(Data_train,Labels_train,i)\n",
    "                    sess.run(self.training_op,feed_dict={self.X:X_batch,self.y:y_batch})\n",
    "\n",
    "                acc_train=self.accuracy.eval(feed_dict={self.X:Data_train,self.y:Labels_train})\n",
    "                acc_val=self.accuracy.eval(feed_dict={self.X:Data_eval,self.y:Labels_eval})\n",
    "                self.tr_err.append(acc_train)\n",
    "                self.val_err.append(acc_val)\n",
    "\n",
    "                print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\",acc_val)\n",
    "\n",
    "            if save_model:\n",
    "                save_path=saver.save(sess,self.filename)\n",
    "\n",
    "\n",
    "    def get_batch(self,X,y,run):\n",
    "\n",
    "        inds=self.indices[self.batch_size*run:self.batch_size*(run+1)]\n",
    "        BX=[]\n",
    "        By=[]\n",
    "        for i in inds:\n",
    "            BX.append(X[i])\n",
    "            By.append(y[i])\n",
    "        return np.array(BX),np.array(By)\n",
    "\n",
    "    def plot_error(self):\n",
    "\n",
    "        fig=plt.figure()\n",
    "        ax1=fig.add_subplot(111)\n",
    "        ax1.plot(self.tr_err,label=\"Training\")\n",
    "        ax1.plot(self.val_err,label=\"Validation\")\n",
    "        ax1.set_xlabel('Epochs')\n",
    "        ax1.set_ylabel('Error')\n",
    "        ax1.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self,Data):\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver=tf.train.Saver()\n",
    "            saver.restore(sess,self.filename)\n",
    "            res=self.logits.eval(feed_dict={self.X:Data})\n",
    "            if self.regression:\n",
    "                return res\n",
    "            else:\n",
    "                return np.argmax(res,axis=1)\n",
    "            \n",
    "    def score(self,Data,Labels):\n",
    "        with tf.Session() as sess:\n",
    "            saver=tf.train.Saver()\n",
    "            saver.restore(sess,self.filename)\n",
    "            return self.accuracy.eval(feed_dict={self.X:Data,self.y:Labels})\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
